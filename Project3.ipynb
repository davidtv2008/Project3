{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project #3:\n",
    "\n",
    "# David Toledo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup, libraries and preprocessing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import sklearn.preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "bank = pandas.read_csv('bank.csv', sep=';')\n",
    "\n",
    "boolean = { 'no': 0.0, 'yes': 1.0 }\n",
    "months = {\n",
    "    'jan': 1.0, 'feb': 2.0, 'mar': 3.0, 'apr': 4.0,  'may': 5.0,  'jun': 6.0,\n",
    "    'jul': 7.0, 'aug': 8.0, 'sep': 9.0, 'oct': 10.0, 'nov': 11.0, 'dec': 12.0\n",
    "}\n",
    "\n",
    "bank.replace({\n",
    "    'default': boolean,\n",
    "    'housing': boolean,\n",
    "    'loan':    boolean,\n",
    "    'month':   months,\n",
    "    'y':       boolean\n",
    "}, inplace=True)\n",
    "\n",
    "# Categorical features\n",
    "#\n",
    "# Since we plan to use logistic regression, add drop_first=True\n",
    "# to use dummy instead of one-hot encoding\n",
    "\n",
    "categorical = ['job', 'marital', 'education', 'contact', 'poutcome']\n",
    "bank = pandas.get_dummies(bank, columns=categorical, prefix=categorical, drop_first=True)\n",
    "\n",
    "# Numeric features\n",
    "#\n",
    "# Standardized because we plan to use KNN and SVM \n",
    "\n",
    "scaled = ['age', 'balance', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous']\n",
    "bank[scaled] = sklearn.preprocessing.scale(bank[scaled].astype(float))\n",
    "\n",
    "# Training set and targets\n",
    "X = bank.drop(columns='y').values\n",
    "t = bank['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# problem #1 Use sklearn.model_selection.train_test_split to set aside 20% of the data as a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem #2 Fit an sklearn.naive_bayes.GaussianNB classifier to your training set. (This is the classifier from Section 5.2.1.5 of the textbook; the classifier in Section 5.2.1.6 is sklearn.naive_bayes.MultinomialNB.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem #3 Use the classifier to predict the targets in the test set. Evaluate your classifierâ€™s performance by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part a Finding its score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = clf.score(X_test,t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part b Creating an sklearn.metrics.confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_matrix = confusion_matrix(t_test,prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part c Plotting an sklearn.metrics.roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/Roc_curve.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part d Compute the sklearn.metrics.roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprob = clf.predict_proba(X_test)[:,1]\n",
    "roc_score = roc_auc_score(t_test, pprob)\n",
    "print(\"Roc auc score: \", roc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roc auc score:  0.7929166050933452"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4 Fit an sklearn.linear_model.LogisticRegression model to your training set, setting fit_intercept to False since the dataset is normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg = LogisticRegression(solver='lbfgs', fit_intercept=False)\n",
    "X_train, X_train_logReg, t_train, t_train_logReg = train_test_split(X_train, t_train, test_size=0.2)\n",
    "logReg.fit(X_train_logReg, t_train_logReg)\n",
    "pprob_logReg = logReg.predict_proba(X_test)[:,1]\n",
    "fpr_rt_lm, tpr_rt_lm, thresh_lm = roc_curve(t_test, pprob_logReg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5 Fit sklearn.svm.SVC models with the 'linear', 'poly', 'rbf', and 'sigmoid' kernel functions. Which kernel performs better on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_lin = SVC(kernel='linear', probability=True, gamma='auto')\n",
    "svc_score_lin = svc_lin.fit(X_train, t_train).decision_function(X_test)\n",
    "fpr_lin, tpr_lin, thresh = roc_curve(t_test, svc_score_lin)\n",
    "\n",
    "svc_pol = SVC(kernel='poly', probability=True, gamma='auto')\n",
    "svc_score_pol = svc_pol.fit(X_train, t_train).decision_function(X_test)\n",
    "fpr_pol, tpr_pol, thresholds = roc_curve(t_test, svc_score_pol)\n",
    "\n",
    "svc_rbf = SVC(kernel='rbf', probability=True, gamma='auto')\n",
    "svc_score_rbf = svc_rbf.fit(X_train, t_train).decision_function(X_test)\n",
    "fpr_rbf, tpr_rbf, thresholds = roc_curve(t_test, svc_score_rbf)\n",
    "\n",
    "svc_sigm = SVC(kernel='sigmoid', probability=True, gamma='auto')\n",
    "svc_score_sigm = svc_sigm.fit(X_train, t_train).decision_function(X_test)\n",
    "fpr_sig, tpr_sig, thresholds = roc_curve(t_test, svc_score_sigm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6 Of the classifiers you fit in experiments (2) through (5), which has the best performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/all_plots.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistics Regression has best score and performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7 ???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
